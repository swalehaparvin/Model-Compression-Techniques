{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPH8UXj/xr+Yqe6oBdhD+Vb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swalehaparvin/Model-Compression-Techniques/blob/main/Knowledge_Distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhQ5twWJcgVE"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertConfig\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"shawhin/phishing-site-classification\")"
      ],
      "metadata": {
        "id": "3K4f7c7XdNM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# Load teacher model and tokenizer\n",
        "model_path = \"shawhin/bert-phishing-classifier_teacher\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "teacher_model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)"
      ],
      "metadata": {
        "id": "3ueeIvIsdlTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load student model\n",
        "my_config = DistilBertConfig(n_heads=8, n_layers=4) # drop 4 heads per layer and 2 layers\n",
        "student_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",config=my_config,).to(device)"
      ],
      "metadata": {
        "id": "y8QtaR96eGKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True)\n",
        "\n",
        "\n",
        "tokenized_data = data.map(preprocess_function, batched=True)\n",
        "tokenized_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
      ],
      "metadata": {
        "id": "figEr9dQeZvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Disable gradient calculations\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass to get logits\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Get predictions\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "EzwZr_DVecIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute distillation and hard-label loss\n",
        "def distillation_loss(student_logits, teacher_logits, true_labels, temperature, alpha):\n",
        "    # Compute soft targets from teacher logits\n",
        "    soft_targets = nn.functional.softmax(teacher_logits / temperature, dim=1)\n",
        "    student_soft = nn.functional.log_softmax(student_logits / temperature, dim=1)\n",
        "\n",
        "    # KL Divergence loss for distillation\n",
        "    distill_loss = nn.functional.kl_div(student_soft, soft_targets, reduction='batchmean') * (temperature ** 2)\n",
        "\n",
        "    # Cross-entropy loss for hard labels\n",
        "    hard_loss = nn.CrossEntropyLoss()(student_logits, true_labels)\n",
        "\n",
        "    # Combine losses\n",
        "    loss = alpha * distill_loss + (1.0 - alpha) * hard_loss\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "R02gNkxNeiEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "lr = 1e-4\n",
        "num_epochs = 5\n",
        "temperature = 2.0\n",
        "alpha = 0.5\n",
        "\n",
        "optimizer = optim.Adam(student_model.parameters(), lr=lr)\n",
        "\n",
        "# create training data loader\n",
        "dataloader = DataLoader(tokenized_data['train'], batch_size=batch_size)\n",
        "# create testing data loader\n",
        "test_dataloader = DataLoader(tokenized_data['test'], batch_size=batch_size)"
      ],
      "metadata": {
        "id": "NFwkc5LnekIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.train()\n",
        "\n",
        "# train model\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in dataloader:\n",
        "        # Prepare inputs\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Disable gradient calculation for teacher model\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs = teacher_model(input_ids, attention_mask=attention_mask)\n",
        "            teacher_logits = teacher_outputs.logits\n",
        "\n",
        "        # Forward pass through the student model\n",
        "        student_outputs = student_model(input_ids, attention_mask=attention_mask)\n",
        "        student_logits = student_outputs.logits\n",
        "\n",
        "        # Compute the distillation loss\n",
        "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} completed with loss: {loss.item()}\")\n",
        "\n",
        "    # Evaluate the teacher model\n",
        "    teacher_accuracy, teacher_precision, teacher_recall, teacher_f1 = evaluate_model(teacher_model, test_dataloader, device)\n",
        "    print(f\"Teacher (test) - Accuracy: {teacher_accuracy:.4f}, Precision: {teacher_precision:.4f}, Recall: {teacher_recall:.4f}, F1 Score: {teacher_f1:.4f}\")\n",
        "\n",
        "    # Evaluate the student model\n",
        "    student_accuracy, student_precision, student_recall, student_f1 = evaluate_model(student_model, test_dataloader, device)\n",
        "    print(f\"Student (test) - Accuracy: {student_accuracy:.4f}, Precision: {student_precision:.4f}, Recall: {student_recall:.4f}, F1 Score: {student_f1:.4f}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # put student model back into train mode\n",
        "    student_model.train()"
      ],
      "metadata": {
        "id": "b24nA-fGenJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create testing data loader\n",
        "validation_dataloader = DataLoader(tokenized_data['validation'], batch_size=8)\n",
        "\n",
        "\n",
        "teacher_accuracy, teacher_precision, teacher_recall, teacher_f1 = evaluate_model(teacher_model, validation_dataloader, device)\n",
        "print(f\"Teacher (validation) - Accuracy: {teacher_accuracy:.4f}, Precision: {teacher_precision:.4f}, Recall: {teacher_recall:.4f}, F1 Score: {teacher_f1:.4f}\")\n",
        "\n",
        "\n",
        "student_accuracy, student_precision, student_recall, student_f1 = evaluate_model(student_model, validation_dataloader, device)\n",
        "print(f\"Student (validation) - Accuracy: {student_accuracy:.4f}, Precision: {student_precision:.4f}, Recall: {student_recall:.4f}, F1 Score: {student_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "0oIlV-syevav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "0pIlAeEJeyw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.push_to_hub(\"swaleha19/bert-phishing-classifier_student\")"
      ],
      "metadata": {
        "id": "G8QpCzfne0PW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}