{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMU9Kh7wVq+9TPHXTNnzGD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swalehaparvin/Model-Compression-Techniques/blob/main/Quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantization is a technique to downsize a trained model so that you can deploy it on EDGE devices. In this notebook we will,\n",
        "\n",
        "(1) Train a hand written digits model\n",
        "\n",
        "(2) Export to a disk and check the size of that model\n",
        "\n",
        "(3) Use two techniques for quantization (1) post training quantization (3) quantization aware training"
      ],
      "metadata": {
        "id": "IeUjrRUAn50M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UXzvC6CVnRso"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "e0QiBviBnf3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed26872c-e3d8-4aeb-9be2-ef9e99dcc869"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFzx1_TRnjXj",
        "outputId": "275721a3-475a-46db-eb6e-e71188f7af5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2AdqYV-nk0W",
        "outputId": "ce13b8f8-2f3d-4ad4-8517-7b707d13c2e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZgMwcV8nmUM",
        "outputId": "4d5e4697-54c2-41a5-b927-a38e43000032"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "kuH0xKAEnn_8",
        "outputId": "06d1d05f-b9e2-4d41-d69a-8b0ed024ff1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d30ad7a1fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMqOk3l_nrVr",
        "outputId": "413eea0d-2c08-49cb-a831-2385ede71341"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.uint8(5)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "X_train_flattened = X_train.reshape(len(X_train), 28*28)\n",
        "X_test_flattened = X_test.reshape(len(X_test), 28*28)\n",
        "X_train_flattened.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH8qOwzintVu",
        "outputId": "d0ad0530-9c01-415a-a214-da2fbec02fbb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Flatten layer so that we don't have to call .reshape on input dataset"
      ],
      "metadata": {
        "id": "qc66JxrVoEud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgPWUkU9oGkc",
        "outputId": "29347ab3-8cbb-4369-f14a-24a57af69f9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.4510\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9599 - loss: 0.1329\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.0845\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9809 - loss: 0.0613\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0476\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d30ac8b8e00>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8om1ZNcoRvM",
        "outputId": "18e3fce7-798a-4b79-ba01-6f1e3d142ea4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.0894\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08060906827449799, 0.9758999943733215]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"./saved_model\"):\n",
        "    os.makedirs(\"./saved_model\")\n",
        "\n",
        "model.save(\"./saved_model/my_model.keras\")"
      ],
      "metadata": {
        "id": "JiTuwwyToTfE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "692f0a34"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"./saved_model\"):\n",
        "    os.makedirs(\"./saved_model\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "X3J9s5hFoxRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post training quantization\n",
        "\n",
        "Without quantization"
      ],
      "metadata": {
        "id": "zYutiW17oywn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaXKu76ioyF8",
        "outputId": "3cd52726-dbb0-4b58-b359-623f2921f18b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpwz17vitu'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  137648006454672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137648006455632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137648006455056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137648006455440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With quantization"
      ],
      "metadata": {
        "id": "jafkK5w5o-uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zbsOmmxo_I3",
        "outputId": "227eb5de-aacc-492f-fe4c-56cd3d0f5328"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmp3orxdl4p'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  137648006454672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137648006455632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137648006455056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137648006455440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3Jsp8E5pFZ-",
        "outputId": "17a4820e-e7c1-4240-c327-18c351f5d444"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "319960"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tflite_quant_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9frmbdI2pHnk",
        "outputId": "4888d4bd-1041-4333-ac87-d346150daece"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86016"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see above that quantizated model is 1/4th the size of a non quantized model"
      ],
      "metadata": {
        "id": "MiwxSrXOpKyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tflite_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "with open(\"tflite_quant_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_quant_model)"
      ],
      "metadata": {
        "id": "nuovs407pOZQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "R24oncuupTDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization aware training"
      ],
      "metadata": {
        "id": "H6ADwJmcpTvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy==1.26.4\n",
        "!pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GhJEB3pTzcS",
        "outputId": "1f0467f6-a26b-4d3e-c508-f7deb73a7447"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the model for quantization aware training\n",
        "model_qat = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_qat.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_qat.fit(X_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njJj8fAbUwsr",
        "outputId": "3708b8f5-3222-4aac-c67c-3ae7fa409690"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8728 - loss: 0.4507\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9590 - loss: 0.1421\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0944\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0673\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0511\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d30ac6a5ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import tf_keras as keras\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "BYZ7JDOXqC0P"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import tf_keras as keras\n",
        "\n",
        "# Recreate the model for quantization aware training\n",
        "model_qat = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "q_aware_model = quantize_model(model_qat)\n",
        "\n",
        "# `quantize_model` requires a recompile.\n",
        "q_aware_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6mGk4znU8iU",
        "outputId": "7bc1373b-30d1-4112-a463-b3db1bf51e80"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLa  (None, 28, 28)            3         \n",
            " yer)                                                            \n",
            "                                                                 \n",
            " quant_flatten (QuantizeWra  (None, 784)               1         \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrapp  (None, 100)               78505     \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_dense_1 (QuantizeWra  (None, 10)                1015      \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79524 (310.64 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 14 (56.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model.fit(X_train, y_train, epochs=1)\n",
        "q_aware_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "ellDiSwQrue6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b2bda4-933c-4c2c-90e0-05f34ba3d80d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2707 - accuracy: 0.9220\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1469 - accuracy: 0.9559\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14689692854881287, 0.9559000134468079]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_qaware_model = converter.convert()"
      ],
      "metadata": {
        "id": "WBjdo2znryXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a7c847-508d-400e-e577-13328ed2ee45"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tflite_qaware_model)"
      ],
      "metadata": {
        "id": "4gLT6w9Kr0CF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c679061b-12c5-4630-d615-26656754fba4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82704"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tflite_qaware_model.tflite\", 'wb') as f:\n",
        "    f.write(tflite_qaware_model)"
      ],
      "metadata": {
        "id": "9RpVZQM4r1Y2"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}